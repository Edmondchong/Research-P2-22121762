# -*- coding: utf-8 -*-
"""split&checkdiseaserow.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BDxhkl6jo0R69Jv4h7ZUulD3mNS8xNWT

# Split 15% for both test and validation
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

# Load the dataset
data = pd.read_csv("/content/drive/MyDrive/P2/T1/Dataset/non_overlapped/4non_overlapped.csv")

# Set the percentage of samples for testing and validation
test_ratio = 0.15  # 15% for testing
val_ratio = 0.15   # 15% for validation
min_samples = 2    # Ensure at least one sample per split

# Initialize lists to hold training, validation, and testing data
training_data = []
validation_data = []
testing_data = []

# Group by disease and split ensuring all diseases are represented
for disease, group in data.groupby("disease_label"):
    total_samples = len(group)
    test_samples = max(int(total_samples * test_ratio), min_samples)
    val_samples = max(int(total_samples * val_ratio), min_samples)

    if total_samples > (test_samples + val_samples):
        # Ensure sufficient samples for training
        test_group = group.sample(n=test_samples, random_state=42)
        remaining_group = group.drop(test_group.index)
        val_group = remaining_group.sample(n=val_samples, random_state=42)
        train_group = remaining_group.drop(val_group.index)
    else:
        # If insufficient samples, split unevenly but ensure representation
        test_group = group.sample(n=min(min_samples, total_samples - 1), random_state=42)
        remaining_group = group.drop(test_group.index)
        val_group = remaining_group.sample(n=min(min_samples, len(remaining_group)), random_state=42)
        train_group = remaining_group.drop(val_group.index)

    testing_data.append(test_group)
    validation_data.append(val_group)
    training_data.append(train_group)

# Combine all splits into final datasets
training_dataset = pd.concat(training_data).reset_index(drop=True)
validation_dataset = pd.concat(validation_data).reset_index(drop=True)
testing_dataset = pd.concat(testing_data).reset_index(drop=True)

# Save the datasets to separate files
training_dataset.to_csv("/content/drive/MyDrive/P2/T1/Dataset/non_overlapped/ML-no-train.csv", index=False)
validation_dataset.to_csv("/content/drive/MyDrive/P2/T1/Dataset/non_overlapped/ML-no-val.csv", index=False)
testing_dataset.to_csv("/content/drive/MyDrive/P2/T1/Dataset/non_overlapped/ML-no-test.csv", index=False)

# Print confirmation and data distribution
print(f"Training dataset saved with {training_dataset.shape[0]} samples.")
print(f"Validation dataset saved with {validation_dataset.shape[0]} samples.")
print(f"Testing dataset saved with {testing_dataset.shape[0]} samples.")

# Optionally, print class distributions
print("\nTraining Data Distribution:")
print(training_dataset['disease_label'].value_counts())

print("\nValidation Data Distribution:")
print(validation_dataset['disease_label'].value_counts())

print("\nTesting Data Distribution:")
print(testing_dataset['disease_label'].value_counts())

"""# Check Disease Row

# LLM set
"""

import pandas as pd

# Load the dataset
file_path = "/content/drive/MyDrive/P2/T1/Dataset/non_overlapped/LLM-no-test.csv"
df = pd.read_csv(file_path)

# Check total number of rows
total_rows = df.shape[0]
print(f"Total number of rows in the dataset: {total_rows}")

# Check number of rows per unique disease
disease_counts = df['disease_label'].value_counts()

# Display disease row counts
disease_df = disease_counts.to_frame().reset_index()
disease_df.columns = ['Disease', 'Row Count']
print(disease_df)

"""# Machine Learning set"""

import pandas as pd

# Load the dataset
file_path = "/content/drive/MyDrive/P2/T1/Dataset/non_overlapped/ML-no-test.csv"
df = pd.read_csv(file_path)

# Check total number of rows
total_rows = df.shape[0]
print(f"Total number of rows in the dataset: {total_rows}")

# Check number of rows per unique disease
disease_counts = df['disease_label'].value_counts()

# Display disease row counts
disease_df = disease_counts.to_frame().reset_index()
disease_df.columns = ['Disease', 'Row Count']
print(disease_df)